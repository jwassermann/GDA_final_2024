{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#009440; padding: 0px; background-size:cover; background-opacity:50%; border-radius:5px; height:300px\">\n",
    "    <div style=\"margin: 5px; padding: 10px;\">\n",
    "    <h1 style=\"color:#00000\">Geophysical Data Acquisition and Analysis</h1>\n",
    "    <h5 style=\"color:#C0C0C0\">LMU, summer 2024</h5>\n",
    "    <h4 style=\"color:rgba(0,0,0,0.6)\">Joachim Wassermann, Sabrina Keil</h4>\n",
    "    </div>\n",
    "    <div style=\"float:right; margin: 20px; padding: 20px; background:rgba(255,255,255,0.7); width: 70%; height: 100px\">\n",
    "        <div style=\"position:relative; top:40%; transform: translateY(-50%)\">\n",
    "        <div style=\"font-size: x-large; font-weight:900; color:rgba(0,0,0,0.8); line-height:100%\">P2.4 - Final exam report </div>\n",
    "        </div>\n",
    "    </div>\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules + deadline\n",
    "\n",
    "In the following you find five exercises plus some basic code. Adapt the code as needed to answer the questions and provide your answers in separate markdown cells below the exercise. Please, do not forget to label axes, lines, titles, etc in your plot. <br>\n",
    "Please, make sure that your answers are as elaborate and detailed as necessary to make your answer clear. However, concentrate on the essentials. \n",
    "\n",
    "In case, you refer to literature/sources outside the course material, do not forget to acknowledge/cite it properly. You are allowed to also include images from outside the notebook if that may help you to explain. Please, do not forget to provide us with the image files then. This is how you import figures: \n",
    "\n",
    "`<img style=\"float: left; height: 350px; padding: 10px\" src=\"DATA/figure.jpg\"/>`\n",
    "\n",
    "For help in coding, please, consult the NB of the practicals and the official [Python](http://docs.python.org/) and [ObsPy](http://docs.obspy.org) documentation. If these helps do not solve your problem, contact one of the lecturers.  \n",
    "For help in formating the markdown cells, you can find help e.g. at the webpage of [wikipedia](https://en.wikipedia.org/wiki/Markdown) or on the [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). In case of severe problems, please, contact us in time.\n",
    "\n",
    "Please, submit your final notebook via mail to Heiner Igel (igel@geophysik.uni-muenchen.de) latest \n",
    "\n",
    "### Friday 06 September 2024, 12:00am (noon) !\n",
    "\n",
    "Notebooks received after that time will not be considered.\n",
    "\n",
    "*Please, do not forget to execute Cell 0 first!*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Name:  \n",
    "## Matrikel number:  \n",
    "\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Preparation for programming\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "# alternative: interactive notebook backend\n",
    "#%matplotlib notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                  # do not show warnings\n",
    "from scipy import interpolate, signal\n",
    "from obspy import read, UTCDateTime, Stream, Trace\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy.signal.cross_correlation import xcorr_pick_correction\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "plt.rcParams['figure.dpi'] = 72\n",
    "plt.rcParams['lines.linewidth'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "\n",
    "## Exercise 1\n",
    "\n",
    "In this exercise you will work on broadband data from the Mw8.2 Chile earthquake from 1st of April 2014 at 23:46:47 UTC recorded at the Black Forest Observatory (`BFO`) in SW Germany which is part of the German Regional Seismic Network (`GR`). The goal of this exercise is to show your understanding of the principal basics in signal processing. Answer the following questions and perform the necessary steps in the corresponding code cells.\n",
    "\n",
    "**a)** In `cell 1a` we fetch the waveforms via the FDSN client of BGR in Hanover and remove the instrument characteristic of the data (no further coding necessary here). We also fetch the event information. Explain what \"removing the instrument response\" means and why it is necessary. Which mathematical method do you connect with this step? What is to consider during instrument response removal? A hint is given by the options used for removing the instrument response. Comment on all of them.\n",
    "\n",
    "**b)** Now that you have downloaded the data and removed the instrument response, which further steps do you need to perform for pre-processing (assuming you want to analyse the data in the frequency domain later on)? Assume that for your scientific task the highest frequency you want to analyse is 5Hz and that the processing workflow will eventually be applied to a large amount of data. Describe the general pre-processing chain and point out the possible pitfalls, their reasons, and how to avoid them. \n",
    "\n",
    "**c)**: Try to plot the ray paths for this specific earthquake-receiver pair. Identify which phases should theoretically be visible in the seismogram. Try to plot them along with the waveform to see if they can be seen in the seismogram.\n",
    "Help for coding can be found [here](https://docs.obspy.org/packages/obspy.taup.html?highlight=taup#module-obspy.taup) and [here](https://docs.obspy.org/packages/autogen/obspy.taup.tau.TauPyModel.get_ray_paths.html?highlight=get%20ray%20path#obspy.taup.tau.TauPyModel.get_ray_paths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1a : getting the waveforms, station inventory and event information\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "client_bgr = Client(\"BGR\")\n",
    "client_usgs = Client(\"USGS\")\n",
    "\n",
    "origin_time = UTCDateTime(\"2014-04-01T23:46:47\")\n",
    "\n",
    "st = client_bgr.get_waveforms(\"GR\", \"BFO\", \"*\", \"BH?\", origin_time, origin_time + (180 * 60))\n",
    "inventory = client_bgr.get_stations(network='GR', station='BFO', channel='BH?', level='response')\n",
    "event = client_usgs.get_events(minmagnitude=8, starttime=origin_time - 100, endtime=origin_time + 100)[0]\n",
    "\n",
    "print(st)\n",
    "\n",
    "plot = True\n",
    "for i, tr in enumerate(st):\n",
    "    # only plot the response removal for one trace..\n",
    "    if i > 0:\n",
    "        plot = False\n",
    "    tr.remove_response(inventory=inventory, output=\"VEL\", pre_filt=None, water_level=30,\n",
    "                       zero_mean=True, taper=True, taper_fraction=0.05, plot=plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1b: pre-processing the data\n",
    "\n",
    "# take a copy of the stream to avoid overwriting the original data\n",
    "bfo = st.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1c - part 1: plot of ray pathes for this EQ-receiver pair\n",
    "\n",
    "# loading some necessary package as a hint ...\n",
    "from obspy.taup import TauPyModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1c - part 2: plot seismogram with theoretical travel times\n",
    "\n",
    "# loading some necessary package as a hint ...\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to exercise 1\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 : Noise Evaluation - Spectral Analysis and I95-Estimation\n",
    "\n",
    "### a) PPSD\n",
    " * read waveform data from file `BW.BDGS..BHN.D.2016.035`\n",
    " * read corresponding station metadata from file `BW_inventory.xml` (the XML files contains most of Bavarias network stations metadata - select the right one).\n",
    " * print info on both waveforms and station metadata\n",
    " * (if `cartopy` package is installed) plot location of station using the inventory's `plot()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: read data, print info, plot inventory\n",
    "from obspy import *\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * compute probabilistic power spectral densities using `PPSD` class from obspy.signal, see http://docs.obspy.org/tutorial/code_snippets/probabilistic_power_spectral_density.html (but use the inventory you read from StationXML as metadata)\n",
    " * plot the processed `PPSD` (`plot()` method attached to `PPSD` object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute PPSD from data\n",
    "from obspy.signal import PPSD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since longer term stacks would need too much waveform data and take too long to compute, I prepared two years continuous data preprocessed for 2 stations on three channels each to play with..\n",
    "\n",
    " * `FUR`: LMU geophysical observatory in Fürstenfeldbruck\n",
    " * `ROTZ`: Rotzenmühle, low-noise station in Bavarian network)\n",
    "\n",
    "\n",
    " * load long term pre-computed PPSD from one of the files `PPSD_(FUR|ROTZ)_(H,E)H?.npz` using `PPSD`'s `load_npz()` staticmethod (i.e. it is called directly from the class, not an instance object of the class)\n",
    " * plot the PPSD (default is full time-range, depending on how much data and spread is in the data, adjust `max_percentage` option of `plot()` option)\n",
    " * do a cumulative plot (which is good to judge non-exceedance percentage dB thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load PPSD from a .npz file\n",
    "FURP = \n",
    "ROTZP = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the PPSD loaded above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * do different stacks of the data using the [`calculate_histogram()` (see docs!)](http://docs.obspy.org/packages/autogen/obspy.signal.spectral_estimation.PPSD.calculate_histogram.html) method of `PPSD` and visualize them\n",
    " * compare differences in different frequency bands qualitatively (anthropogenic vs. \"natural\" noise)..\n",
    "   * nighttime stack, daytime stack\n",
    " * (Gold card members: Use the `callback` option and use some crazy custom callback function in `calculate_histogram()`, e.g. stack together all data from birthdays in your family.. or all German holidays + Sundays in the time span.. or from dates of some bands' concerts on a tour.. etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do specific histogram stacks and plot, compare differences qualitatively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * do different stacks of the data using the [`calculate_histogram()` (see docs!)](http://docs.obspy.org/packages/autogen/obspy.signal.spectral_estimation.PPSD.calculate_histogram.html) method of `PPSD` and visualize them\n",
    " * compare differences in different frequency bands qualitatively (anthropogenic vs. \"natural\" noise)..\n",
    "   * weekdays stack, weekend stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do specific histogram stacks and plot, compare differences qualitatively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * do different stacks of the data using the [`calculate_histogram()` (see docs!)](http://docs.obspy.org/packages/autogen/obspy.signal.spectral_estimation.PPSD.calculate_histogram.html) method of `PPSD` and visualize them\n",
    " * compare differences in different frequency bands qualitatively (anthropogenic vs. \"natural\" noise)..\n",
    "   * seasonal stacks (e.g. northern hemisphere autumn vs. spring/summer, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do specific histogram stacks and plot, compare differences qualitatively\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * do different stacks of the data using the [`calculate_histogram()` (see docs!)](http://docs.obspy.org/packages/autogen/obspy.signal.spectral_estimation.PPSD.calculate_histogram.html) method of `PPSD` and visualize them\n",
    " * compare differences in different frequency bands qualitatively (anthropogenic vs. \"natural\" noise)..\n",
    "   * stacks by specific month\n",
    "   * maybe even combine several of above restrictions.. (e.g. only nighttime on weekends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: do specific histogram stacks and plot, compare differences qualitatively\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer a)\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) I95\n",
    " \n",
    " A very simple alternative to evaluate the noise condition at a specific site is to estimate the 95% quartile of amplitudes in a pre-defined frequency band and time window. For further information of this method we refer to Groos and Ritter, (2009) https://academic.oup.com/gji/article-pdf/179/2/1213/5996922/179-2-1213.pdf\n",
    " \n",
    " * read waveform data from file `noise_UH2_EHZ.mseed`\n",
    " * read station metadata from file `station_UH2.stationxml`\n",
    " * print info on waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read data, print info, plot inventory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * work with a copy of the first trace in the stream\n",
    " * use inventory with the trace's [`remove_response(..) (see docs!)`](http://docs.obspy.org/packages/autogen/obspy.core.trace.Trace.remove_response.html) method to remove the frequency response from the data (use `plot=True` to visualize what is going on in frequency domain), going to ground velocity (ending up in `m/s`)\n",
    " * after instrument correction filter to a frequency band of choice (usually something like 0.5-20 Hz for local to regional event detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: remove response, filter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * multiply the trace's underlying data array with `1e9` to get to `nm/s`\n",
    " * use numpy's `abs()` and `percentile()` functions, to compute the 95th percentile of absolute values in the data (due to the response removal and filtering the data should already be zero-mean -- which is of course a requirement)\n",
    " * print the I95 value of the 3 hours of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate and print I95 of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * here we do the I95 calculation in a smaller moving window over time to get some statistics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import seaborn\n",
    "from obspy import read, read_inventory\n",
    "\n",
    "#read data noise_UH2_EHZ.mseed\n",
    "st = \n",
    "#read station metadata\n",
    "inv =\n",
    "\n",
    "#select the first trace in the stream\n",
    "tr = \n",
    "\n",
    "#remove instrument response ()\n",
    "tr\n",
    "\n",
    "#filter between 0.5-20 Hz\n",
    "tr\n",
    "\n",
    "#compute I95 for 10 minute time windows (no coding needed after here)\n",
    "t = tr.stats.starttime\n",
    "# 10 minute moving window\n",
    "step = 10 * 60\n",
    "i95_list = []\n",
    "\n",
    "while t + step < tr.stats.endtime:\n",
    "    data = np.abs(tr.slice(t, t+step)) * 1e9\n",
    "    i95 = np.percentile(data, 95)\n",
    "    i95_list.append(i95)\n",
    "    t += step\n",
    "\n",
    "#plot\n",
    "plt.figure()\n",
    "try:\n",
    "    import seaborn\n",
    "except ImportError:\n",
    "    plt.violinplot(i95_list)\n",
    "else:\n",
    "    seaborn.violinplot(i95_list, orient=\"v\", cut=0)\n",
    "plt.ylabel(\"I95 [nm/s]\")\n",
    "plt.figure()\n",
    "plt.plot(i95_list)\n",
    "plt.xlabel(\"moving windows\\n({} -- {})\".format(\n",
    "    tr.stats.starttime.strftime(\"%F %r\"), tr.stats.endtime.strftime(\"%F %r\")))\n",
    "plt.ylabel(\"I95 [nm/s]\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give a statement about the performance of this station. What is the advantage, what the disadvantage of I95 in comparison to the PSD estimate?\n",
    "\n",
    "#### Answer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 : Estimating the effect of wind turbines \n",
    "\n",
    "We use in the following a couple of methods defined in src/i_95.py. You are asked to use different smoothing values for estimating the I95 in a frequency band between 1 - 20 Hz for data recroded at station VIEL (NE-Bavaria).\n",
    "\n",
    "a) Use the I95SDSClient to estimate the I95 values with different smoothing parameters and plot the result using the i95 plotting function. Use the matplotlib twin plotting option to plot also the wind speed which was recorded at station Hof. What do you see? \n",
    "\n",
    "b) Use the numpy cross-correlation functionality to estimate possible dependencies between the different data sets. What easy tool you can use in order to see if a linear relationship exists between the two data traces? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib nbagg\n",
    "\n",
    "import sys\n",
    "from obspy import UTCDateTime\n",
    "sys.path.append('./src/')\n",
    "from i95_sds import I95SDSClient\n",
    "\n",
    "\n",
    "\n",
    "i95_sds_root = './data/'\n",
    "\n",
    "i95_client = I95SDSClient(i95_sds_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading also wind data\n",
    "start = UTCDateTime(2013, 5, 7)\n",
    "end = UTCDateTime(2021, 5, 7)\n",
    "\n",
    "datum = []\n",
    "wind = []\n",
    "wind_max = []\n",
    "\n",
    "fh = open(\"data/produkt_klima_tag_19470101_20211231_02261.txt\",\"r\")\n",
    "line = fh.readline()\n",
    "while 1:\n",
    "    line = fh.readline()\n",
    "    if not line: break;\n",
    "    data = line.split(\";\")\n",
    "    datum.append(data[1])\n",
    "    wind.append(float(data[4]))\n",
    "    wind_max.append(float(data[3]))\n",
    "\n",
    "start_str = \"%04d%02d%02d\"%(start.year,start.month,start.day)\n",
    "end_str = \"%04d%02d%02d\"%(end.year,end.month,end.day)\n",
    "times = []\n",
    "\n",
    "starty = start\n",
    "while starty < end:\n",
    "    times.append(starty.matplotlib_date)\n",
    "    starty = starty + 24*3600\n",
    "\n",
    "windm = wind[datum.index(start_str):datum.index(end_str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nslc = [\n",
    "    ('BW', 'VIEL', '', 'EHZ'),\n",
    "    ('BW', 'VIEL', '', 'EHN'),\n",
    "    ('BW', 'VIEL', '', 'EHE'),\n",
    "    ]\n",
    "\n",
    "grouped = {}\n",
    "for n, s, l, c in nslc:\n",
    "    netstaloc = '.'.join((n, s, l))\n",
    "    grouped.setdefault(netstaloc, []).append((n, s, l, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i95_client = I95SDSClient(\n",
    "    i95_sds_root,\n",
    "    smoothing_step_hours=,\n",
    "    smoothing_window_length_hours=,\n",
    "    smoothing_valid_percentage=,\n",
    "    smoothing_percentile=,\n",
    "    smoothing_mean=)\n",
    "\n",
    "fig, ax = i95_client.plot_all_data(#to be filled)\n",
    "ax1 = ax.twinx()\n",
    "#...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer a) ...   \n",
    "\n",
    "#### Answer b) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "This question is about convolution of signals. You are provided with two signals. \n",
    "\n",
    "a) What is a convolution? Convolution is closely connected to a special kind of system. Which one? Describe the connection. <br> \n",
    "Using [signal.convolve](http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve.html) convolve the two signals in Cell 4a. Set the mode='same'. Explain the meaning of the mode parameter. <br>\n",
    "Plot the original signals and the convolved signal. Be careful to plot the entire signal on both the x and y axes. Include labels. Are convolutions commutative? \n",
    "\n",
    "b) In cell 4b, convolve the signals win and sig in the reverse order, continuing to use mode='same'. Replot. <br>\n",
    "Are the results the same or different from cell 4a? Explain this result. Explain any inconsistencies.\n",
    "\n",
    "c) Bonus: Amend the signals so that convolving them in the reverse order gives the same result as convolving them in original order. Hint: There are two possible solutions to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 4a - convolving two signals + plotting\n",
    "\n",
    "# make a box car function\n",
    "sig = np.repeat([0., 1., 0.], 100)\n",
    "# make a Hann window \n",
    "win = signal.hann(50)\n",
    "\n",
    "# convolve the signals\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4b - convolution in reverse order + plotting\n",
    "\n",
    "# make a box car function\n",
    "sig = np.repeat([0., 1., 0.], 100)\n",
    "# make a Hann window \n",
    "win = signal.hann(50)\n",
    "\n",
    "# convolve the signals IN REVERSE ORDER\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4c - amend signals and convolve again (bonus)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to exercise 4\n",
    "\n",
    "a) ...  \n",
    "\n",
    "b) ...  \n",
    "\n",
    "c) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "## Exercise 5\n",
    "\n",
    "\n",
    "In Cell 5a theoretical gravity data, modeled for the location in Wettzell, are loaded. The data show a superposition of tidal effects due to different celestial bodies. Here is a short overview of the most important ones, sorted according the amplitude of their influence on Earth:\n",
    "+ tides with a period of half a day from sun, moon, Mars, Jupiter, etc. ..., period: 0.5 day \n",
    "+ tides with a period of one day from sun, moon, Mars, Jupiter, etc. ..., period: 1 days\n",
    "+ cycle of the orbit of the moon, period: 28 days\n",
    "+ equinox - sun and moon passing the equator plane, period: 186 days (about every six months)\n",
    "+ Chandler wobble (deviation of Earth's axis of rotation relative to the solid Earth), period: 433 days\n",
    "+ effects due to further planets ....\n",
    "\n",
    "\n",
    "a) In Cell 5b, calculate the spectrum of the data (what is that?) and plot it (as a log-log plot). What is the Nyquist frequency of the data. Try to identify the different tidal effects and name the frequencies of their peak positions. Why is the peak for the Chandler wobble not really visible in the spectrogram?\n",
    "Hint: For calculating the spectrum, you can use the function [periodogram](http://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.signal.periodogram.html) of the scipy.signal package.  \n",
    "If you want to mark the separate tides in the plot, you can use [matplotlib.axvline()](http://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.axvline.html).  \n",
    "**Bonus**: Between the full day tide and the moon orbit is another distinct peak in the spectrum. What frequency is it and can you explain its causes?\n",
    "\n",
    "b) In Cell 5c, try to separate the first two tides (half day and full day tide) together from the other tidal effects. Which filter do you choose and why? Plot the filtered signal for the first 20 days.  \n",
    "Generally spoken, what is filtering (what happens in terms of digital data analysis)?   \n",
    "What different kinds of filters do you know in terms of frequency range?. Describe them.    \n",
    "How many different ways of providing a characterisitc of a specific filter do you know? Describe them.\n",
    "\n",
    "c) Now, isolate the half day and full day tides separately from each other. Which filter do you choose this time and why? Plot the filtered signals for the first 20 days on top of the filtered data from exercise 5b (You should have now 1 plot with 3 traces now). What differences do you see (consider amplitude and phase)? Explain the differences. With respect to the phase of the data, is there something you would like to change? What and Why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5a - reading and plotting gravity data\n",
    "# read in gravity data, modeled for Wettzell, Germany. Units is in nm/s^2 vertical acceleration. \n",
    "filename = 'data/gravity.dat'\n",
    "\n",
    "# prepare to input data into obspy Stream\n",
    "data = np.loadtxt(filename, dtype='float32', comments=\"#\")\n",
    "stats = {'network': 'XX', 'station': 'WETZ', 'location': '',\n",
    "         'channel': 'XZ', 'npts': len(data), 'delta': 3600}\n",
    "\n",
    "stats['starttime'] = UTCDateTime(\"2015,01,01,00,00,00\")\n",
    "s = Stream([Trace(data=data, header=stats)])\n",
    "\n",
    "# write as MSEED file\n",
    "s.write(\"gravity.mseed\", format='MSEED')\n",
    "\n",
    "# test that it worked, read stream from file and plot\n",
    "st = read(\"gravity.mseed\")\n",
    "print(st)\n",
    "print(st[0].stats)\n",
    "#st.plot()\n",
    "\n",
    "plt.plot(st[0].times()/(3600*24), st[0].data, color='b')\n",
    "plt.xlim(0,365)\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"gravity [m/s^2]\")\n",
    "plt.show()\n",
    "\n",
    "# zoom into first 35 days\n",
    "plt.plot(st[0].times()[0:800]/(3600*24), st[0].data[0:800], color='b')\n",
    "plt.xlabel(\"time [days]\")\n",
    "plt.ylabel(\"gravity [m/s^2]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5b - calculate spectrum\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5c - filtering the data\n",
    "\n",
    "HP = st.copy()\n",
    "BP = st.copy()\n",
    "BP2 = st.copy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to exercise 5\n",
    "\n",
    "a) ...   \n",
    "\n",
    "b) ...  \n",
    "\n",
    "c) ...  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________\n",
    "\n",
    "## Exercise 6\n",
    "\n",
    "In this question we are going to use a cross correlation technique to make a differential pick time. You are provided with two signals in the data directory: \n",
    "\n",
    "`data/seismogram_1.MSEED` <br>\n",
    "`data/seismogram_2.MSEED`\n",
    "\n",
    "seismogram_2.MSEED is noisy, and arrives later than seismogram_1.MSEED. We will use a cross-correlation with the better seismogram to make a more accurate pick of the arrival time on the noisy seismogram. \n",
    "\n",
    "For this question you should use the obspy function [xcorr_pick_correction()](https://docs.obspy.org/packages/autogen/obspy.signal.cross_correlation.xcorr_pick_correction.html). This is well documented, and has good default plotting options. \n",
    "\n",
    "You are given these initial pick times. <br>\n",
    "t1 = UTCDateTime(0.335)<br>\n",
    "t2 = UTCDateTime(0.55)\n",
    "\n",
    "a) Read in the seismograms in Cell 6a. Use the function [xcorr_pick_correction](https://docs.obspy.org/packages/autogen/obspy.signal.cross_correlation.xcorr_pick_correction.html) to create a cross correlation. There is no need to filter the seismograms.  <br>\n",
    "Plot the cross correlation. Display the Time correlation and Correlation coefficient.\n",
    "\n",
    "b) What was the length of the time window you cross-correlated over? Why is this a good choice?  \n",
    "\n",
    "c) Calculate the corrected differential pick time in Cell 6b. This is the time lag between the first arrival on seismogram 1 and on seismogram 2.\n",
    "\n",
    "d) Write a short paragraph on what has been done here, and why it could be useful. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6a - crosscorrelation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6b - differential pick times\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to exercise 6:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
